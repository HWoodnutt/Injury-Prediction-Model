---
title: "PFM - Injury Data"
author: "Harry Woodnutt"
date: "2025-08-15"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r, results='hide', message=FALSE, warning=FALSE}
if (!require("devtools")){
  install.packages("devtools")
}
if (!require("worldfootballR")){
  devtools::install_github("JaseZiv/worldfootballR")
}
```

```{r}
library(worldfootballR)
library(tidyverse)
library(dplyr)
```
#Get a list of all player urls from all teams in the top 5 european leagues
# saved as 'all_player_urls'

```{r}
library(worldfootballR)
library(purrr)
library(readr)
library(dplyr)

# File path for saved CSV
file_path <- "all_player_urls_tm.csv"

if (file.exists(file_path)) {
  message("Reading saved data from CSV...")
  all_player_urls <- read_csv(file_path, show_col_types = FALSE)$all_player_urls
} else {
  message("CSV not found. Scraping data...")

  # Step 1: Define the leagues and season
  leagues <- c(
    "England",  # Premier League
    "France",   # Ligue 1
    "Germany",  # Bundesliga
    "Italy",    # Serie A
    "Spain"     # La Liga
  )
  season_start <- 2024

  # Step 2: Get all team URLs for each league
  all_team_urls <- map(leagues, ~ tm_league_team_urls(country_name = .x, start_year = season_start)) %>%
    unlist()

  # Step 3: Get player URLs for each team
  all_player_urls <- map(all_team_urls, ~ {
    Sys.sleep(1)  # polite delay to avoid being blocked
    tryCatch(
      tm_team_player_urls(.x),
      error = function(e) {
        message("Error fetching ", .x)
        return(NULL)
      }
    )
  }) %>% unlist()

  # Step 4: Save CSV with stable column name
  write_csv(tibble(all_player_urls = all_player_urls), file_path)
}

# Step 5: Preview
head(all_player_urls)
length(all_player_urls)

```
# Use the list of player URL's to get a complete list of injuries for all players in the list
```{r}
library(purrr)
library(readr)

# File path for saved CSV
file_path <- "all_injuries_tm.csv"

if (file.exists(file_path)) {
  message("Reading saved injury data from CSV...")
  all_injuries <- read_csv(file_path)
} else {
  message("CSV not found. Scraping injury data...")

  all_injuries <- map2_dfr(
    all_player_urls,
    seq_along(all_player_urls),
    ~ {
      message("Fetching player ", .y, " of ", length(all_player_urls))
      Sys.sleep(1) # polite delay

      tryCatch(
        {
          tm_player_injury_history(.x)
        },
        error = function(e) {
          message("Error fetching ", .x, ": ", e$message)
          return(NULL)  # skip player if failed
        }
      )
    },
    .id = "player_index"
  )

  # Save to CSV for next time
  write_csv(all_injuries, file_path)
}

# Preview
head(all_injuries)
```


#Data Filtering (Recent injuries)
```{r}
library(dplyr)
library(stringr)

injuries_filtered <- all_injuries %>%
  # Extract the first two digits of the season's starting year and convert to numeric
  filter(as.numeric(substr(season_injured, 1, 2)) >= 21) %>%
  mutate(season_start = as.numeric(substr(season_injured, 1, 2)))

glimpse(injuries_filtered)
```

```{r}
sapply(injuries_filtered, class)
```

#Data Cleaning
```{r}
library(dplyr)
library(readr)

injuries_filtered <- injuries_filtered %>%
  mutate(
    duration = parse_number(duration)  
    )  

glimpse(injuries_filtered)
```



```{r}
library(dplyr)

injuries_filtered %>%
  select(
    player_index, player_name, season_injured, season_start,
    injury, injured_since, injured_until, duration, games_missed
  ) %>%
  arrange((player_index), injured_since) %>%
  print(n = 20)   # show first 20 rows, adjust n as needed
```

#create unique list of injuries to allow for injury grouping
```{r}
library(dplyr)
library(readr)

unique_injuries_list <- injuries_filtered %>%
  select(injury) %>%       # keep only the injury description
  distinct() %>%           # keep only unique values
  arrange(injury)          # optional: sort alphabetically

unique_injuries_list
write_csv(unique_injuries_list, "unique_injuries_list.csv")
```

#injury list taken offline and grouped by ChatGPT
#Below the injuries with groupings are read back into R Studio
```{r}
library(readr)
colnames(injuries_grouped_complete) <- c("injury", "injury_group")
head(injuries_grouped_complete)
```

#merge actual injury dataset with injury mappings list 
```{r}
# Merge with the mapping table
injuries_filtered <- injuries_filtered %>%
  left_join(injuries_grouped_complete, by = "injury")

# Check results
head(injuries_filtered)
```

#View data type of each column in injuries_filtered
```{r}
sapply(injuries_filtered, class)
```


#summarise injury list per player
```{r}
library(dplyr)

injury_summary <- injuries_filtered %>%
  group_by(player_index, player_url, player_name) %>%  # Or whatever column identifies the player
  summarise(
    injury_count_last_3_seasons = sum(season_start < 24, na.rm = TRUE),
    days_missed_last_3_seasons = sum(duration[season_start < 24], na.rm = TRUE),
    injury_count_last_2_seasons = sum(season_start > 21 & season_start < 24, na.rm = TRUE),
    days_missed_last_2_seasons = sum(duration[season_start > 21 & season_start < 24], na.rm = TRUE),
    injury_count_last_1_seasons = sum(season_start == 23, na.rm = TRUE),
    days_missed_last_1_seasons = sum(duration[season_start == 23], na.rm = TRUE),
    
    muscular_injury_count_last_3_seasons = sum(season_start < 24 & injury_group == 'Muscular', na.rm = TRUE),
    muscular_days_missed_last_3_seasons = sum(duration[season_start < 24 & injury_group == 'Muscular'], na.rm = TRUE),
    muscular_injury_count_last_2_seasons = sum(season_start > 21 & season_start < 24 & injury_group == 'Muscular', na.rm = TRUE),
    muscular_days_missed_last_2_seasons = sum(duration[season_start > 21 & season_start < 24 & injury_group == 'Muscular'], na.rm = TRUE),
    muscular_injury_count_last_1_seasons = sum(season_start == 23 & injury_group == 'Muscular', na.rm = TRUE),
    muscular_days_missed_last_1_seasons = sum(duration[season_start == 23 & injury_group == 'Muscular'], na.rm = TRUE),
     
    skeletal_injury_count_last_3_seasons = sum(season_start < 24 & injury_group == 'Skeletal', na.rm = TRUE),
    skeletal_days_missed_last_3_seasons = sum(duration[season_start < 24 & injury_group == 'Skeletal'], na.rm = TRUE),
    skeletal_injury_count_last_2_seasons = sum(season_start > 21 & season_start < 24 & injury_group == 'Skeletal', na.rm = TRUE),
    skeletal_days_missed_last_2_seasons = sum(duration[season_start > 21 & season_start < 24 & injury_group == 'Skeletal'], na.rm = TRUE),
    skeletal_injury_count_last_1_seasons = sum(season_start == 23 & injury_group == 'Skeletal', na.rm = TRUE),
    skeletal_days_missed_last_1_seasons = sum(duration[season_start == 23 & injury_group == 'Skeletal'], na.rm = TRUE),
    
    tendon_ligament_injury_count_last_3_seasons = sum(season_start < 24 & injury_group == 'Tendon/Ligament', na.rm = TRUE),
    tendon_ligament_days_missed_last_3_seasons = sum(duration[season_start < 24 & injury_group == 'Tendon/Ligament'], na.rm = TRUE),
    tendon_ligament_injury_count_last_2_seasons = sum(season_start > 21 & season_start < 24 & injury_group == 'Tendon/Ligament', na.rm = TRUE),
    tendon_ligament_days_missed_last_2_seasons = sum(duration[season_start > 21 & season_start < 24 & injury_group == 'Tendon/Ligament'], na.rm = TRUE),
    tendon_ligament_injury_count_last_1_seasons = sum(season_start == 23 & injury_group == 'Tendon/Ligament', na.rm = TRUE),
    tendon_ligament_days_missed_last_1_seasons = sum(duration[season_start == 23 & injury_group == 'Tendon/Ligament'], na.rm = TRUE),
    
    days_missed_current_season = sum(duration[season_start == 24], na.rm = TRUE),

    )

injury_summary
```

```{r}
#Now we look to add FBRef data, to do so we need to use the player mapping table to join FBRef data to TM data
library(worldfootballR)
library(readr)
library(dplyr)

# File path for saved CSV
file_path <- "mapped_players.csv"

if (file.exists(file_path)) {
  message("Reading saved player mapping from CSV...")
  mapped_players <- read_csv(file_path)
} else {
  message("CSV not found. Fetching player mapping...")

  mapped_players <- player_dictionary_mapping()

  # Save for next time
  write_csv(mapped_players, file_path)
}

# Preview
head(mapped_players)
```


```{r}
library(dplyr)

injury_summary_enriched <- injury_summary %>%
  left_join(
    mapped_players %>% select(UrlTmarkt, UrlFBref),
    by = c("player_url" = "UrlTmarkt"))

# View result
library(dplyr)

# Rearrange columns so fbref_url is near the front
injury_summary_enriched <- injury_summary_enriched %>%
  select(UrlFBref, everything()) %>%
  rename(
     fbref_url = UrlFBref,
     transfermarkt_url = player_url 
  )


# View the result
head(injury_summary_enriched)

```

```{R}
library(rvest)
library(httr)
library(dplyr)
library(stringr)
library(purrr)
library(readr)

get_player_bio_info_table <- function(url) {
  res <- GET(url, user_agent("Mozilla/5.0"))
  page <- read_html(res)
  
  labels <- page %>%
    html_nodes(".info-table__content--regular") %>%
    html_text2() %>% str_squish()
  
  values <- page %>%
    html_nodes(".info-table__content--bold") %>%
    html_text2() %>% str_squish()
  
  values <- str_replace_all(values, "\\s+", " ")
  bio <- setNames(values, labels)
  bio_df <- as_tibble(as.list(bio))
  
  colnames(bio_df) <- colnames(bio_df) %>%
    str_replace_all("\\s|/|:", "") %>%
    str_replace_all("__+", "") %>%
    str_replace_all("-", "") %>%
    str_trim()
  
  return(bio_df)
}
```

```{R}
# Fetch all player bios

file_path <- "all_player_bio.csv"

if (file.exists(file_path)) {
  message("Reading saved player bio data from CSV...")
  all_player_bio <- read_csv(file_path)  # use same variable name
} else {
  message("CSV not found. Scraping player bio data...")

all_player_bio <- map2_dfr(
  all_player_urls,
  seq_along(all_player_urls),
  ~{
    message("Fetching player ", .y, " of ", length(all_player_urls))
    Sys.sleep(3)
    
    tryCatch(
      {
        get_player_bio_info_table(.x)
      },
      error = function(e) {
        message("Failed to fetch: ", .x)
        return(tibble())  # skip if error
      }
    )
  },
  .id = "player_index"
)

# Save to CSV
write_csv(all_player_bio, file_path)
}

print(all_player_bio)
```
```{r}
# urls you actually scraped successfully
scraped_index <- unique(all_player_bio$player_index)  # or whatever column has it  

# real failed urls
failed_urls <- setdiff(all_urls, worked_urls)

length(all_urls)       # should be 2075
length(worked_urls)    # should match your successful rows
length(failed_urls)    # should be 2075 - length(worked_urls)

# save
writeLines(failed_urls, "failed_player_urls.txt")
```
```{r}
unique_player_index <- unique(injury_summary_enriched$player_index)
print(unique_player_index)
```


```{r}
library(dplyr)

urls_to_rescrape <- injury_summary_enriched %>%
  filter(player_index %in% failed_index) %>%
  pull(transfermarkt_url)

print(urls_to_rescrape)
```


#retry for failed urls
```{r}
library(dplyr)
library(purrr)
library(readr)

file_path <- "all_player_bio.csv"

# Step 1: Load existing successfully scraped data
if (file.exists(file_path)) {
  message("Reading saved player bio data from CSV...")
  all_player_bio <- read_csv(file_path)
} else {
  stop("Original CSV not found. You need the base dataset first.")
}

# Step 2: Scrape only the failed URLs
failed_player_bio <- map2_dfr(
  urls_to_rescrape,  # your vector of failed URLs
  seq_along(urls_to_rescrape),
  ~{
    message("Fetching failed player ", .y, " of ", length(urls_to_rescrape))
    Sys.sleep(3)  # polite pause between requests
    
    tryCatch(
      {
        get_player_bio_info_table(.x)
      },
      error = function(e) {
        message("Failed again: ", .x)
        return(tibble())  # skip if error
      }
    )
  },
)
```


```{r}
max_index <- max(as.numeric(all_player_bio$player_index))
failed_player_bio <- failed_player_bio %>%
  mutate(player_index = seq(max_index + 1, length.out = n()))
```

```{r}
head(failed_player_bio)

```


```{r}
all_player_bio_1 %>% 
  filter(player_index == 1)
print()
```

```{R}
failed_player_bio <- failed_player_bio %>%
  mutate(player_index = as.numeric(player_index))

# Step 3: Combine with the original data
all_player_bio_updated <- bind_rows(all_player_bio, failed_player_bio)
# Step 4: Save updated dataset
write_csv(all_player_bio_updated, file_path)

# Preview
print(all_player_bio_updated)
```

#player bio cleaning
```{r}
library(dplyr)
library(stringr)

all_player_bio_clean <- all_player_bio_updated %>%
  separate(
    col = Position,
    into = c("Position_1", "Position_2"),
    sep = " - ",
    fill = "right",   # if there's no "-" it will keep Position_2 as NA
    extra = "merge") %>%
  
  mutate(
    Fullname = coalesce(Fullname, Nameinhomecountry),
    Age = str_extract(DateofbirthAge, "(?<=\\().+?(?=\\))") %>% as.numeric(), 
    Height = Height %>%
      str_remove(" m") %>%        
      str_replace(",", ".") %>% 
      as.numeric(),  
    Position_2 = ifelse(is.na(Position_2) | Position_2 == "", "Goalkeeper", Position_2), 
    Foot = if_else(is.na(Foot), "right", Foot)


     
  ) %>%
  
   group_by(Position_1) %>%
  mutate(
    Height = if_else(
      is.na(Height),
      round(mean(Height, na.rm = TRUE), 2),
      round(Height, 2)
    )
  ) %>%
  ungroup() %>%
  
  select(
    -Nameinhomecountry, -Placeofbirth, -Playeragent, -Joined, 
    -Contractexpires, -Lastcontractextension, -Outfitter, 
    -SocialMedia, -Onloanfrom, -Contractthereexpires, 
    -Contractoption, -Dateofdeath, -DateofbirthAge, -Citizenship,
    -`2ndclub`, -`3ndclub`
  ) 
 


```

```{r}
print(all_player_bio_clean)
```

```{r}
write_csv(all_player_bio_clean, "all_player_bio_clean.csv")
```

```{r}
head(injury_summary_enriched)
```

```{r}
library(dplyr)

injury_summary_enriched_with_bio <- injury_summary_enriched %>%
  left_join(
    all_player_bio_clean,
    by = "player_index"
  )

print(injury_summary_enriched_with_bio)
```

```{r}
all_player_bio_ederson <- failed_player_bio %>%
  filter(player_index == 1)
print(all_player_bio_ederson)
```